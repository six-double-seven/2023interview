# 操作系统

# 1. 什么是操作系统

- 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序
- 操作系统向下屏蔽了底层硬件的复杂性，向上提供统一接口，为用户使用计算机提供了便利
- 操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

# 进程&线程&协程

>概念

1.进程

- 进程是程序的一次执行过程，是系统运行程序的基本单位。

- 进程拥有自己独立的地址空间，有自己的堆，上级挂靠单位是操作系统
- 操作系统会以进程为单位，分配系统资源（CPU时间片、内存等资源），**进程是操作系统资源分配的最小单位**。

2.线程

- 线程是进程的更小的执行单元，多个线程共同协作完成某一项任务

- 线程，有时被称为轻量级进程(Lightweight Process，LWP），是**操作系统调度（CPU调度）执行的最小单位**。

3.协程

-  协程是一种**用户态的轻量级线程**，协程不被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

- 协程在子程序内部是可中断的，然后转而执行别的子程序，在适当的时候再返回来接着执行。

>对比

1.协程 vs 多线程

- 极高的执行效率：因为子程序切换不是线程切换，而是由程序自身控制，因此没有线程切换的开销，和多线程相比，线程数量越多，协程的性能优势就越明显；
- 不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

# 上下文切换

线程在执行的过程中会有自己的运行条件和状态(上下文)，比如上文说过的程序计数器、栈信息等

出现上下文切换的情况：

- 主动放弃cpu，比如调用sleep()、wait()
- cpu时间片用完
- 调用了阻塞类型的系统中断，比如请求io、线程被阻塞

以上三种情况均发生了线程切换，线程切换意味着需要保存当前线程的上下文(等待下次获得cpu时间时恢复现场)，并且加载下一个将要获得cpu时间片的线程上下文。

# 2. 什么是系统调用

> 介绍系统调用之前，我们先来了解一下用户态和系统态。

- 根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：
  - 用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。
  - 系统态(kernel mode):系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。
- 我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的**系统态级别**的子功能时就需要系统调用了！
- 也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如内存管理、文件管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。
- 这些系统调用按功能大致可分为如下几类：
  - 设备管理。完成设备的请求或释放，以及设备启动等功能。
  - 文件管理。完成文件的读、写、创建及删除等功能。
  - 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能
  - 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
  - 进程通信。完成进程之间的消息传递或信号传递等功能。

# 3. 死锁产生的必要条件

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
- **持有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
- **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
- **循环等待**：在进程-资源分配图中表现为有环，有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

# 4. 如何解决死锁

>处理死锁的思路

- 预防死锁、避免死锁、检测死锁、解除死锁

## 4.1 预防死锁

> 破坏四个必要条件(互斥、持有并等待、非抢占、循环等待)中的一个或者多个来预防死锁；

- 破坏 **互斥条件**：使得资源是可以同时访问的，但是显然有很多资源 **往往是不能同时访问的** ，所以这种做法在大多数的场合是行不通的。
- 破坏 **非抢占** ：也就是说可以采用 **剥夺式调度算法**，但剥夺式调度方法目前一般仅适用于 **主存资源** 和 **处理器资源** 的分配，并不适用于所以的资源，会导致 **资源利用率下降**。
- 破坏**持有并等待**：**静态分配策略**
  - 所谓静态分配策略，就是指一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。进程要么占有所有的资源然后开始执行，要么不占有资源，不会出现占有一些资源等待一些资源的情况。静态分配策略逻辑简单，实现容易，但这种策略 **严重地降低了资源利用率**。

- 破坏了**循环等待**：**层次分配策略**
  - 在层次分配策略下，所有的资源被分成了多个层次，一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源，按这种策略，是不可能出现循环等待链的。

## 4.2 避免死锁

> 在分配资源之前进行判断，只允许不会产生死锁的进程获得资源；

- 我们将系统的状态分为 **安全状态** 和 **不安全状态** ，每当在申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。
- 最具有代表性的 **避免死锁算法** 就是 Dijkstra 的银行家算法，当一个进程申请使用资源的时候，**银行家算法** 通过先 **试探** 分配给该进程资源，然后通过 **安全性算法** 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则 **分配资源给该进程**。

## 4.3 检测死锁

- 对资源的分配加以限制可以 **预防和避免** 死锁的发生，但是都不利于各进程对系统资源的**充分共享**，类比来讲的话，死锁的预防和避免类似于悲观锁，而死锁的检测和接触类似于乐观锁。
- 检测死锁指系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的**进程和资源**。

## 4.4 解除死锁

- **立即结束所有进程的执行，重新启动操作系统** ：这种方法简单，但以前所在的工作全部作废，损失很大。
- **撤销涉及死锁的所有进程，解除死锁后继续运行** ：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
- **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
- **抢占资源** ：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除

# 5. 进程的状态

进程大概有5种状态，分别是new、ready、running、waiting、terminated状态，5种状态的状态的转换如下。

>整体流程

- 当创建进程结束会处于new状态，当得到除了cpu时间片以外的全部资源时，跳转为就ready状态，当获得了cpu时间片即刻进入running状态，处于running状态的进程如果需要某一资源或者等待某一事件会进入到waiting状态，当获得相应的资源后会再次进入到ready队列中等待事件片；当进程正常结束或因为其他原因中断退出即为结束状态。

>说明

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

# 6. 线程间同步的方式

> 线程同步是两个或多个共享关键资源的线程的并发执行, 应该同步线程以避免关键的资源使用冲突。

操作系统一般有下面三种线程同步的方式：

1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

# 7. 进程间互斥的方式

- 上锁
- 严格轮换法(孔融让梨)
  - turn 实现在两个进程之间转换，每次执行完代码对turn进行更新
  - 问题：进程们需要严格交替进入临界区，如果有一个进程比较霸道一直处于临界区，那其他进程只能等待

![image-20220707080929424](http://six-double-seven.oss-cn-beijing.aliyuncs.com/img/image-20220707080929424.png)

- Peterson算法
  - 如果当前turn为自身，并且对方的interested为true，则执行循环进行等待

![image-20220707081228731](http://six-double-seven.oss-cn-beijing.aliyuncs.com/img/image-20220707081228731.png)

# 8. 进程间同步的方式

## 8.1 信号量

- 信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。
  - **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
  - **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

- down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。
- 如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```java
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

# 9.[进程间通信](https://www.jianshu.com/p/c1015f5ffa74)

## 9.1 什么是进程间通信IPC

- 每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过**内核**；
- 在内核中开辟一块缓冲区，进程1把数据从**用户空间**拷到**内核缓冲区**，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**

## 9.2 常见的进程间通信方式

- 主要分为两大类 共享内存和消息传递

![image-20220414194920229](http://six-double-seven.oss-cn-beijing.aliyuncs.com/img/image-20220414194920229.png)

### 9.2.1 共享内存(Shared memory)

- 使得多个进程可以直接读写同一块内存空间，是最快的可用IPC形式，是针对其他通信机制运行效率较低而设计的。
- 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。
  - 实现互斥：上锁、turn严格轮换法、peterson算法(孔融让梨)
  - 实现同步：生产者-消费者问题(有界缓冲区问题)   ---  信号量
- **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。

### 9.2.2 消息传递(管道和消息队列)

>管道的实质

- 管道是用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名pipe文件。写进程以字符流形式将大量的数据写入管道；即读进程则从管道中接收数据。

>匿名管道的局限性

- 只支持单向数据流
- 只能用于亲缘关系的进程之间
- 管道的缓冲区有限

>有名管道(FIFO)

- 提供了一个**路径名**和有名管道关联，有名管道的名字存在于文件系统中，内容存放在内存中；
- 即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信，因此，通过有名管道不相关的进程也能交换数据；
- 有名管道严格遵循**先进先出(FIFO)**，对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾

> 消息(Message)队列

- 消息队列是存放在**内核**中的消息链表，每个消息队列由消息队列标识符表示。
- 管道和消息队列的通信数据都是先进先出的原则
- 与管道不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
- 消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达

### 9.2.3 套接字

- 主要用于在客户端和服务器之间通过网络进行通信
- 套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点
- 简单的说就是通信双方的一种约定，用套接字中的相关函数来完成通信过程。

# 10. 进程的调度算法

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

# 11. 内存管理介绍

- 操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存）
- 另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。

# 12. 内存管理机制

>为每个进程建立各自的地址空间，使用基址寄存器和界限寄存器来对进程区域划定界限，但现在已经不再使用，这种方式需要保证一个进程必须连续且完整的加载到内存中，

- 简单分为**连续分配管理方式**和**非连续分配管理方式**这两种
- 连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。
- 非连续分配管理方式允许一个程序使用的内存分布在不相邻的内存中，常见的如**页式管理** 、 **段式管理**、**段页式管理**

1. **块式管理** ： 老计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。每块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过**页表**对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过**段表**对应逻辑地址和物理地址。
4. **段页式管理机制** 。段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，这样既拥有了分段系统的共享和保护，又拥有分页系统的虚拟内存功能。另外段页式管理机制 中段与段之间以及段的内部的都是**离散**的，
4. 简单来说：页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。

# 13.分页机制和分段机制的共同点和区别

> 共同点

- 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

>区别

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。

- 大小是否可变：页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。

- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。


#  14 虚拟内存

- 虚拟内存的目的是为了让物理内存扩充成更大的虚拟内存，从而让程序获得更多的可用内存。
- 为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。
- 虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

**综上所述：**

- 通过 **虚拟内存** 可以让程序拥有超过系统物理内存大小的可用内存空间
- 虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉，每个进程拥有一片连续完整的内存空间。这样会更加有效地管理内存并减少出错。

---

其他：

- 将内存分为一个个小单元，称为页面，其中只有一部分的页面会在内存中，当cpu需要访问的地址不在内存中时，在磁盘中加载对应的部分，同时内存不够时也可以把长期不访问的页面保存到磁盘中。

- **虚拟内存**是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**。

- 基于**局部性原理**，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的存储器——**虚拟内存**。

  实际上，虚拟内存同样是一种时间换空间的策略，利用 CPU 的计算时间、页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。

# 15. 虚拟内存的实现

虚拟内存的实现有以下三种方式：

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了**请求调页功能和页面置换功能**。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了**请求调段功能、分段置换功能**。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

不管是上面那种实现方式，我们一般都需要：

1. 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换

# 16 页面置换算法

>介绍

- 地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 ，**缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 
- 当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

>分类

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。

# 17. 逻辑(虚拟)地址和物理地址

- 我们编程一般只和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解为逻辑地址，逻辑地址由操作系统决定；
- 物理地址指的是真实物理内存中地址，就是内存地址寄存器中的地址，物理地址是内存单元真正的地址。

# 18. CPU寻址

- 现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式，**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件

>为什么要有虚拟地址空间呢？|| 直接暴露物理地址的缺点

没有虚拟地址空间的时候，**程序直接访问和操作的都是物理内存** ，会存在以下问题

- 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
- 想要同时运行多个程序特别困难，因为应用程序赋值后会覆盖此前的值，造成上一个程序崩溃。比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

>虚拟地址访问内存有以下优势

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离，不同进程中的同一个VA被MMU映射到不同的PA,并且在某一个进程中访问任何地址都不可能访问到另外一个进程的数据，这样使得任何一个进程由于执行错误指令或恶意代码导致的非法内存访问都不会意外改写其它进程的数据，不会影响其它进程的运行，从而保证整个系统的稳定性。

# 19. 局部性原理

> 局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。
3. 时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。
4. 空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。

**总：**虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存
