# java集合

>集合的概述

- java集合也叫做容器，由两大接口派生而来，分别为colletcion和map两个接口；
  ![](http://six-double-seven.oss-cn-beijing.aliyuncs.com/img/java-collection-hierarchy.1727461b.png)


# 一、Collection接口

# 1. List 

| 子接口     | 底层         | 线程是否安全 |
| ---------- | ------------ | ------------ |
| LinkedList | 双向链表     | 不安全       |
| ArrayList  | Object[]数组 | 不安全       |
| Vector     | Object[]数组 | 安全         |

## 1.1 ArrayList 和 Vector区别

- 线程安全方面：ArrayList 是线程非安全的，而Vector是线程安全的，大部分的方法使用synchronized进行修饰；

- 底层实现方面：二者底层均采用object[]数组存储。

## 1.2 ArrayList 和 LinkedList区别

- 线程安全：二者都是线程不安全的；
- 底层数据结构：ArrayList底层是object[]类型的数组，LinkedList底层是双向链表；
- 是否支持快速的随机访问：ArrayList支持快速的随机访问(ArrayList实现了`RandomAccess`)，LinkedList不支持；
- 插入和删除是否受元素的影响：
  - ArrayList采用数组存储，所以**插入和删除**的时间复杂度受元素位置的影响;
  - LinkedList是链表进行存储，所以在**头部和尾部**插入或者删除元素不受位置的影响，如果是在指定位置进行或者删除的话，时间复杂度是O(n)。

## 1.3 ArrayList的扩容机制

- ArrayList有三个构造方法：无参构造、带初始容量参数的构造函数、带Collection集合的构造函数；
- ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右);

```java
    private void grow(int minCapacity) {
        int newCapacity = oldCapacity + (oldCapacity >> 1);
    }
```

## 1.4 ArrayList的特点

- ArrayList是线程非安全的
  - 在多线程环境下可以考虑用 `Collections.synchronizedList(List l)`函数返回一个线程安全的ArrayList类；

- 实现三个接口
  - 实现了RandomAccess接口，标识着其支持随机快速访问；
  - 实现了Cloneable接口，标识着可以它可以被复制(**浅拷贝**)；
  - 实现了Serializable，支持序列化传输。
- **自动扩容** 
  - 底层使用数组实现，默认**初始容量为10**，当超出后会自动扩容为原来的1.5倍左右，即**自动扩容**机制；
  - **自动扩容：** 数组的扩容是新建一个大容量（原始数组大小+扩充容量）的数组，然后将原始数组数据拷贝到新数组，将新数组作为扩容之后的数组，数组扩容的操作代价很高。
- 采用了**Fail-Fast**机制
  - 当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被**自身或者其他线程**改变，那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件；

# 2. Set

| 子接口        | 底层              | 特点                           |
| ------------- | ----------------- | ------------------------------ |
| HashSet       | 基于`HashMap`实现 | 无序且唯一                     |
| TreeSet       | 红黑树            | 有序且唯一，默认自然排序(升序) |
| LinkedHashSet | LinkedHashMap     |                                |

## 2.1 comparable 和 Comparator 的区别

>包和方法

- `comparable` 接口实际上是出自`java.lang`包 它有一个 `compareTo(Object obj)`方法用来排序
- `comparator`接口实际上是出自 java.util 包它有一个`compare(Object obj1, Object obj2)`方法用来排序

>使用的位置

- Comparable 是默认的比较接口，Comparable 和需要比较的对象紧密结合到一起，即实现该接口必须在类内部实现Comparable 接口并重写compareTo方法；
- Comparator 可以分离比较规则，用在任何地方，所以它更具灵活性。

>其他

- 一个类实现了 **Camparable** 接口则表明这个类的对象之间是可以相互比较的，这个类对象组成的集合就可以直接使用 sort 方法排序。

- Comparator 可以看成一种算法的实现，将算法和数据分离，Comparator 也可以在下面两种环境下使用
  - 类没有考虑到比较问题且未实现 Comparable，可以通过 Comparator 来实现排序而不必改变对象本身
  - 可以使用多种排序标准，比如升序、降序等

## 2.2 无序性和不可重复性的含义

- 无序性不等于随机性，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加，而是根据数据的哈希值决定；
- 不可重复性是指添加元素按照equals()判断时，返回false；

## 2.2 HashSet、TreeSet、LinkedHashSet

- 三者都是Set接口的实现类，都能保证元素的唯一性，都不是线程安全的；
- 三者的底层数据结构不同且三者的应用场景不同
  - HashSet底层是哈希表，基于HashMap实现；
  - LinkedHashSet底层是哈希表和链表，元素的插入和取出满足FIFO；
  - TreeSet底层是红黑树

## 2.3 HashSet && LinkedHashSet 特点

>HashSet 

- 不能保证元素的排列顺序，顺序有可能发生变化
- 不是同步的
- 集合元素可以是null,但只能放入一个null

>LinkedHashSet 

- LinkedHashSet使用链表维护元素的次序(因为使用LinkedHashMap)，这样使得元素看起来像是以**插入顺序**保存的；当遍历该集合时候，LinkedHashSet将会以元素的**添加顺序**访问集合的元素；

## 2.4 hashSet 如何判断重复

- HashSet 内部使用 HashMap 存储元素，对应键值对的键为 Set 的存储元素，值为一个默认的Object 对象；
- HashSet 通过存储元素的 hashCode 方法和 equals 方法来确定元素是否重复;
- HashSet 的**add**方法，其实是直接调用了hashmap的put方法，第一个参数 e代表了存入的元素，第二个元素PRESENT其实是一个定义且初始化好的 new Object。如果该元素在map中不存在，则调用put方法返回null即add方法返回true，反之如果map中存在该元素，调用put方法返回旧的value值即add方法返回false。

```java
    public boolean add(E e) {
        //put()方法 如果插入的 key 对应的 value 已经存在，则执行 value 替换操作，返回旧的 value值，如果不存在则执行插入，返回 null。
        return map.put(e, PRESENT)==null;
    }
```

# 3. Queue

| 子接口        | 底层                        |
| ------------- | --------------------------- |
| PriorityQueue | Object[]数组,数组实现二叉堆 |
| LinkedList    | 红黑树                      |
| ArrayQueue    | Object[]数组 + 双指         |

## 3.2 ArrayQueue、LinkedList的区别

- 二者均实现了Deque接口，均具有队列的功能；

- 底层实现不同：ArrayQueue的底层是可变长的数组和双指针，而LinkedList是通过链表实现；

- 是否支持null数据：ArrayQueue不支持Null数据，如果插入空数据会报空指针异常；而LinkedList支持null；

- 性能方面：

  - `ArrayDeque` 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)；

  - 虽然 `LinkedList` 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢；

    从性能的角度上，选用 `ArrayDeque` 来实现队列要比 `LinkedList` 更好。

## 3.3 谈一谈 PriorityQueue

`PriorityQueue` 是在 JDK1.5 中被引入的, 其与 `Queue` 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。

这里列举其相关的一些要点：

- `PriorityQueue` 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据
- `PriorityQueue` 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。
- `PriorityQueue` 是非线程安全的，且不支持存储 `NULL` 和 `non-comparable` 的对象。
- `PriorityQueue` 默认是小顶堆，但可以接收一个 `Comparator` 作为构造参数，从而来自定义元素优先级的先后。

`PriorityQueue` 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第K大的数、带权图的遍历等，所以需要会熟练使用才行。

# 二、Map接口

| 子接口            | 底层                      | 特点                                   |
| ----------------- | ------------------------- | -------------------------------------- |
| HashMap           | 数组+链表                 | 无序不可重复(不可重复由equals方法保证) |
| ConcurrentHashMap | Node 数组 + 链表 / 红黑树 |                                        |
| HashTable         | 数组                      |                                        |
| LinkedHashMap     | 数组+链表+双向链表        |                                        |

# 1. HashMap

![image-20220511083037058](http://six-double-seven.oss-cn-beijing.aliyuncs.com/img/map-laodu.png)

## 1.1 HashMap的数据结构

- 数组+链表
- hashmap本质是一个**Entry**类型的数组，每个Entry存有key、value、hash以及指向下一个元素的引用；
- 当向HashMap中put(key,value)时，会首先通过**hash算法**计算出存放的位置索引 为i，将其放入到Entry[i]中，如果这个位置上面已经有元素了，那么就将新加入的元素放在链表的头上**最先加入的元素在链表尾**，Entry数组中存储的是最后插入的元素。、
- HashMap在不指定容量的情况下的默认容量为16，HashMap则要求一定为2的整数次幂，因为2的次数可以达到最大限度的散列均匀；
- 如果重写equals方法，则必须冲下hashcode方法。因为在存储的过程中，先调用hashcode()方法再调用equals()方法。

## 1.2 HashMap中hash冲突的解决

>jdk1.8之前

- 使用链表解决哈希冲突

> jdk1.8以后 

- 当链表的长度大于阈值(默认为**8**) 时，会将链表转换为红黑树，减少搜索时间；
- 但在转换为红黑树之前，还需判断当前的数组长度是否**小于64**，如果小于64则会先选择进行数组的扩容，为不是转换为红黑树；

>为什么引入红黑树

- 链表来存储hash值一样的key-value. 如果按照链表的方式存储，随着节点的不断增加会导致查询节点的时间复杂度增加， 为了提高查询效率，故在JDK１.8中引入了改进方法红黑树。此数据结构的平均查询效率为Ｏ(logn) 。


## 1.3 HashMap插入数据如何计算数据的下标

>1.计算哈希码

- 通过hashCode()计算；

>2.二次处理哈希码（扰动处理）

- h  ^ (h >>> 16)

>3.最终计算存储的数组位置

- (n - 1)  & h

>4.覆盖 or 拉链法

如果当前位置存在元素的话，判断该元素与要存入的元素的hash值以及key值是否相同

- 如果相同就直接覆盖；

- 不相同就通过拉链法解决冲突；

>5.为什么和length-1相与而不是和length呢？

length-1的意义在于，length是2的倍数，所以length-1在二进制来说每位都是1，这样可以保证最大的程度的散列hash值

## 1.4 hash值的计算

```java
    static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^ ：按位异或
      // >>>:无符号右移，忽略符号位，空位都以0补齐
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
```

- 当key值为null，hash值为0，即可证明HashMap的key可为null；
  - 对比于HashTable，HashTable的key若为null，则会抛出异常；
- key不为null时，首先计算出hashCode()记作h，然后对h进行扰动处理(按位异或自身**右移16位**后的二进制)。

>为什么要右移16位呢?

- 由于最终是要和 **length - 1**运算，length绝大多数情况小于2的16次方。所以始终是 hashcode 的低16位（甚至更低）参与运算；
- 假如高16位也参与运算，会让得到的下标更加散列；

>为什么采用异或^操作呢？

为了使得到的下标更加散列；

假设均匀随机（1位）输入，AND函数输出概率分布分别为75％ 0和25％ 1；OR为25％ 0和75％ 1；

XOR函数为50％ 0和50％ 1，因此异或操作相对来讲分布的更均匀；

>HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？

hashCode()方法返回的是int整数类型，其范围为-(2 ^ 31)~(2 ^ 31 - 1)，约有40亿 个映射空间，而HashMap的容量范围是在16（初始化默认值）~2 ^ 30，HashMap 通常情况下是取不到最大值的，并且设备上也难以提供这么多的存储空间，从而导致通过hashCode()计算出的哈希值可能不在数组大小范围内，进而无法匹配存储位置。因此我们需要对hashCode()取到的值进行一个扰动。

## 1.5 [扩容](https://blog.csdn.net/lkforce/article/details/89521318)

- 每次添加一个新的元素，都要判断当前容量是否大于**initailCapacity*loadFactor**，如果大于则进行扩容；

>jdk1.7

- 原table的Node放到新的table中，使用的是**头插法**，也就是说，新table中链表的顺序和旧列表中是相反的，在HashMap线程不安全的情况下，这种头插法可能会导致环状节点。

>jdk1.8

- 由于扩容数组的长度是 2 倍关系，所以对于假设初始 tableSize = 4 要扩容到 8 来说就是 0100 到 1000 的变化(左移一位就是 2 倍);

- 在扩容中只用判断原来的 hash 值与左移动的一位（newtable 的值）按位与操作是 0 还是 1；
  - 0 的话索引就不变，1 的话索引变成原索引加上原table长度；

## 1.6 String类适合做hashmapkey的原因

>设计hashCode() 最重要的因素是 对**同一个对象**调用hashCode()应该产生相同的值。

- String中缓存有个hash变量，它可以缓存hashCode，并且String不可变因此避免重复计算hashCode；
- String 类型的对象对这个条件有着很好的支持，因为 String 对象的 hashCode() 值是根据 **String 对象的内容**计算的；即使两个字符串对象的引用不同，但只要值相同，它们的hashcode就相同，就可以索引到相同的value；

- String 对象底 层是一个 final 修饰的 char 类型的数组，hashCode() 的计算是根据字符数组的**每个元素**进行计算的，所以内容相同的 String 对象会产生相同的散列码。

## 1.7 哈希和哈希冲突

>哈希

- 哈希又称为散列 ，将任意长度的输入通过散列算法，变换成固定长度的输出，该输出就是散列值（哈希值）；
- 这种转换是一种压缩映射,即散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。

>哈希冲突

- 不同的输入通过同一散列函数可能会散列成相同的输出，即哈希冲突；

>散列函数基本特性

- 根据同一散列函数计算出的散列值如果不同，那么 输入值肯定也不同；
- 根据同一散列函数计算出的散列值如果相同（哈希冲突情况）， 输入值不一定相同。

## 1.8 解决哈希冲突的方式

> 开放定址法

它是使用一种探测的方式，在整个数组中寻找另一个可以存储值的地方。

- 线性探测

- 再平方探测

- 伪随机探测

  按顺序决定哈希值时，如果某数据已经存在，通过**随机函数**随机生成一个数，在原来哈希值的基础上加上随机数，直至不发生哈希冲突；

>链地址法(拉链法)

在每个位桶实现的时候，采用链表去存取发生哈希冲突的关键字key。

>再散列法

如果使用哈希函数去散列一个输入的时候，输出是同一个位置就**再次散列**，直至不发生冲突;	**缺点:**每次冲突都要重新散列，计算时间增加;

## 1.9 HashMap和HashTable的区别

> 1.继承的父类不同 

- HashMap继承自AbstractMap类；

- Hashtable继承自Dictionary类；
- 二者都实现了Map接口

>2.线程安全性不同

- Hashmap是线程不安全的；
  - (1)如果多个线程同时使用put方法添加元素，而且假设正好存在两个put的key发生了碰撞(hash值一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会有其中一个线程的数据被覆盖；
  - (2)如果多个线程同时检测到元素个数超过数组大小*loadFactor，这样就会发生多个线程同时对Node数组进行扩容，都在重新计算元素位置以及复制数据，但是最终只有一个线程扩容后的数组会赋给table，也就是说其他线程的都会丢失。
- Hashtable是线程安全的，多个线程可以共享一个Hashtable；
- Hashtable 中的方法是synchronized的，而HashMap中的方法在缺省情况下是非Synchronize的。 在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步，但使用 HashMap时就必须要自己增加同步处理。

>3.key和value是否允许null值 

- HashMap中，null可以作为key值，这样的键只有一个；可以有一个或多个键所对应的value值为null。当**get()**方法返回null值时，可能是HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用**containsKey()**方法来判断；

- Hashtable中，key和value都不允许出现null值。

>4.hash值不同

- HashTable直接使用对象的hashCode；
- HashMap会对hashCode()进行扰动处理。

>5.数组初始化

- HashTable在不指定容量的情况下的默认容量为11，而HashMap为16，Hashtable不要求底层数组的容量一定要为2的整数次幂，而HashMap则要求一定为2的整数次幂；

> 6.扩容方式不同

Hashtable扩容时，将容量变为原来的2倍加1，而HashMap扩容时，将容量变为原来的2 倍。

- Hashtable扩容方式为什么是2n+1

  为了保证数组的length值是一个素数，对素数取余可以保证余数的均匀分布，降低冲突率。

## 1.10 负载因子为什么会影响HashMap性能

> 负载因子表示一个散列表空间的使用程度

- 每次添加一个新的元素，都要判断当前容量是否大于initailCapacity*loadFactor，如果大于则进行扩容；

-  负载因子loadFactor越大则散列表的装填程度越高，也就是能容纳更多的元素，导致链表的长度增加，索引效率就会降低；
-  反之，负载因子越小则链表中的数据量就越稀疏，此时会对空间造成浪费，但是索引效率高。

## 1.11 HashMap的put()返回值

- 如果插入的 key 对应的 value 已经存在，则执行 value 替换操作，返回<font color=#FF0033>**旧的 value**</font> 值，如果不存在则执行插入，返回 **null**。

# 2. ConcurrentHashMap

## 2.1 ConcurrentHashMap1.7 存储结构

![image-20220328194848289](http://six-double-seven.oss-cn-beijing.aliyuncs.com/img/image-20220328193054704.png)

- ConcurrnetHashMap由多个**segment**组成，而每一个segment是一个类似于HashMap的结构且每一个HashMap的内部可以进行扩容。
- concurrencyLevel(并发级别)：segment的个数一旦初始化就不能改变，默认Segment的个数是16个，即concurrentHashMap 默认支持最多16个线程并发。
- **锁分段技术**：
  - HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程都必须竞争同一把锁。那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率。
  - 所谓锁分段技术是指首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 另外，ConcurrentHashMap可以做到**读取数据不加锁**，并且其内部的结构可以让其在进行写操作的时候能够将**锁的粒度**保持地尽量地小，不用对整个ConcurrentHashMap加锁。

## 2.2 ConcurrentHashMap1.7的数据结构

- ConcurrentHashMap是一个Segment数组，且每一个segment是一个类似于HashMap的结构且每一个HashMap的内部可以进行扩容；
- Segment通过继承**ReentrantLock**来进行加锁，写操作时只需对元素所在的segment进行加锁。所以每次需要加锁的操作锁住的是一个segment，这样只要保证每个Segment是线程安全的，也就实现了全局的线程安全。

## 2.3 ConcurrentHashMap1.8 存储结构

![image-20220328193054704](http://six-double-seven.oss-cn-beijing.aliyuncs.com/img/image-20220328194848289.png)

-  **Node 数组 + 链表 / 红黑树**。当冲突链表达到一定长度时，链表会转换成红黑树。
-  使用CAS + synchronized 实现

## 2.4 ConcurrentHashMap1.8怎么保证并发

使用 **Node** + **CAS** + **Synchronized**+ **volatile** 来保证并发安全

- **Node**：保存key、value、hash、next的数据结构，其中value和next都用**volatile**修饰，保证并发的可见性；

- **CAS**(compare and swap)比较交换。CAS是一种基于锁的操作，而且是乐观锁。

  在java中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后， 下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加**version**来获取数据，性能较悲观锁有很大的提高。

>volatile 关键字

- Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保将变量的更新操作**通知到其他线程**。当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是**共享**的，因此不会将该变量上的操作与其他内存操作一起重排序;
- volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值;
- 在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比sychronized关键字更轻量级的同步机制

>CAS(compare and swap)

**背景**：假设有多个线程想要操作同一个资源对象，第一反应可能是互斥锁，但互斥锁的同步方式是悲观的，如果大部分调用时读操作或者同步代码块执行的耗时远远小于线程切换的耗时，则不需要使用悲观锁。

**过程：**

- 资源状态为0时代表空闲，1代表占用
- 每个线程都有两个值，old value 代表之前读到的资源对象的状态值，new value代表想要将资源对象的状态值更新后的值；
- 线程获得时间片后，将old value与资源对象的状态值进行compare
  - 如果一致，则将资源状态的值更新为new value；
  - 如果不一致，则使其**自旋**，即不断的重试CAS操作，通常会配置自旋次数来防止死循环；

- compare 和 swap 必须绑定，即两个操作在同时只能有一个线程操作。

**CAS应用：**

使用3条线程，将1个值从0累加至1000；

- 线程不安全

```java
public class Main {

    static int num = 0;
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++){
            Thread thread = new Thread(new Runnable() {
                @Override
                public void run() {
                    while (num < 1000){
                        num++;
                        System.out.println("thread name: " + Thread.currentThread().getName() +":"+num);
                    }
                }
            });
            thread.start();
        }
    }
}
```

- 使用synchronized

```java
public class Main {

    static int num = 0;
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++){
            Thread thread = new Thread(new Runnable() {
                @Override
                public void run() {
                    synchronized (Main.class){
                        while (num < 1000){
                            num++;
                            System.out.println("thread name: " + Thread.currentThread().getName() +":"+num);
                        }
                    }
                }
            });
            thread.start();
        }
    }
}
```

- 使用AtomicInteger(底层使用CAS实现同步)

```java
public class Main {

    static AtomicInteger num = new AtomicInteger(0);
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++){
            Thread thread = new Thread(new Runnable() {
                @Override
                public void run() {
                    synchronized (Main.class){
                        while (num.get() < 1000){
                            System.out.println("thread name: " + Thread.currentThread().getName() +":"+num.incrementAndGet());
                        }
                    }
                }
            });
            thread.start();
        }
    }
}
```

# 3. HashTable

## 3.1 Hashtable多线程下与concurrentHashMap

- 二者均是线程安全的，concurrentHashMap在多线程下效率更高；
- hashtable使用一把锁处理并发问题，当有多个线程访问时，需要多个线程竞争一把锁，导致阻塞；
- 而concurrentHashMap使用分段或者CAS操作来保证并发。

# 4. LinkedHashMap

## 4.1 LinkedHashMap与hashMap

-  二者均是线程不安全的；
-  HashMap无序，而LinkedHashMap有序，可分为**插入顺序**和**访问顺序**两种。如果是访问顺序，那put和get操作已存在的Entry时，都会把Entry移动到双向链表的表尾 (其实是先删除再插入);
-  LinkedHashMap继承自HashMap，是基于HashMap和双向链表来实现的。

## 4.2 LinkedHashMap怎样维护双向链表

- 在LinkedHashMap中每个节点都进行了双向的连接，维持插入的顺序；head指向第一个插入的节点，tail指向最后一个节点。
- LinkedHashMap底层是 数组+单向链表+双向链表。数组+单向链表是HashMap的结构，用来记录数据；双向链表用来记录数据的插入顺序；

## 4.3 LinkedHashMap使用场景

- 如果要求按照**put的顺序**来进行哈希表的遍历，选择LinkedHashMap；

## 4.4 插入顺序和访问顺序

>插入顺序

- LinkedHashMap中的元素在进行遍历输出打印的时候，可以按照put的顺序进行打印；


>访问顺序

- **accessOrder** 为true代表开启访问顺序；
- 开启访问顺序后，只要调用**get**方法，就会执行**afterNodeAccess**方法，将该元素放到链表的最末端；