[TOC]

# 并发编程

# 并发编程的三个重要特性

1. **原子性** : 一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。`synchronized` 可以保证代码片段的原子性。
2. **可见性** ：当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。
3. **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化。



# 并发编程的缺点

并发编程的⽬的就是为了能提⾼程序的执⾏效率，提⾼程序运⾏速度，但是并发编程并不总是能提⾼程序运⾏速度的，

⽽且并发编程可能会遇到很多问题，⽐如**：内存泄漏、上下文切换、线程安全、死锁**等问题。、

内存泄漏：向系统申请分配内存，使用后并未归还给系统。表现为随着程序的运行，当前页面的内存持续走高，造成内存浪费



# 并发编程 & 多线程编程

并发编程是大量的数据同时访问一个接口或者一个方法，举个生活的例子，早高峰进地铁站，一群人蜂拥进站，这可以认为是一种并发，他们要做的事情是一样的：进站。 

那么多线程是什么，如果地铁站的一个闸机口认为是一个线程，那么开放多个闸机口就可以认为是多线程。

多线程编程并不是只在并发的时候用到，它是为了避免一个线程的过载影响效率，多线程也可以将单任务截取为多段同时进行，这种情况的多线程并不是为了处理并发，而是提高效率。好比植树节种树，每个人相当于一个线程，很多人相当于多个线程，大家同时种树只是为了提高效率。

另外并发编程也有其他的实现途径，比如函数式编程



# 上下文切换

线程的上下文是指某一时间点 CPU 寄存器和程序计数器的内容；

CPU切换前把当前任务的状态保存下来(以便下次切换回这个任务时可以再次加载这个任务的状态)，然后加载下一任务的状态并执行。任务的状态保存及再加载, 这段过程就叫做上下文切换。

>总结

**任务状态从保存到再加载的过程就是⼀次上下⽂切换**

多线程编程中⼀般线程的个数都⼤于 CPU 核⼼的个数，⽽⼀个 CPU 核⼼在任意时刻只能被⼀个线程使⽤，为了让这些线程都能得到有效执⾏，CPU 采取的策略是为每个线程分配时间⽚并轮转的形式。当⼀个线程的时间⽚⽤完的时候就会重新处于就绪状态让给其他线程使⽤，这个过程就属于⼀次上下⽂切换。

概括来说就是：当前任务在执⾏完 CPU 时间⽚切换到另⼀个任务之前会先保存⾃⼰的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态，**任务状态从保存到再加载下一个任务状态的过程就是⼀次上下⽂切换**

> 出现上下文切换的情况：

- 主动放弃cpu，比如调用sleep()、wait()
- cpu时间片用完
- 调用了阻塞类型的系统中断，比如请求io、线程被阻塞

以上三种情况均发生了线程切换，线程切换意味着需要保存当前线程的上下文(等待下次获得cpu时间时恢复现场)，并且加载下一个将要获得cpu时间片的线程上下文。



# 什么是系统调用

> 介绍系统调用之前，我们先来了解一下用户态和系统态。

- 根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：
  - 用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。
  - 系统态(kernel mode):系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。
- 我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的**系统态级别**的子功能时就需要系统调用了！
- 也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如内存管理、文件管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。
- 这些系统调用按功能大致可分为如下几类：
  - 设备管理。完成设备的请求或释放，以及设备启动等功能。
  - 文件管理。完成文件的读、写、创建及删除等功能。
  - 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能
  - 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
  - 进程通信。完成进程之间的消息传递或信号传递等功能。



# 死锁产生的必要条件

- **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
- **持有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
- **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
- **循环等待**：在进程-资源分配图中表现为有环，有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。



# 4. 如何解决死锁

>处理死锁的思路

- 预防死锁、避免死锁、检测死锁、解除死锁

## 4.1 预防死锁

> 破坏四个必要条件(互斥、持有并等待、非抢占、循环等待)中的一个或者多个来预防死锁；

- 破坏 **互斥条件**：使得资源是可以同时访问的，但是显然有很多资源 **往往是不能同时访问的** ，所以这种做法在大多数的场合是行不通的。
- 破坏 **非抢占** ：也就是说可以采用 **剥夺式调度算法**，但剥夺式调度方法目前一般仅适用于 **主存资源** 和 **处理器资源** 的分配，并不适用于所有的资源，会导致 **资源利用率下降**。
- 破坏**持有并等待**：**静态分配策略**
  - 所谓静态分配策略，就是指一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。进程要么占有所有的资源然后开始执行，要么不占有资源，不会出现占有一些资源等待一些资源的情况。静态分配策略逻辑简单，实现容易，但这种策略 **严重地降低了资源利用率**。

- 破坏了**循环等待**：**层次分配策略**
  - 在层次分配策略下，所有的资源被分成了多个层次，一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源，按这种策略，是不可能出现循环等待链的。

## 4.2 避免死锁

> 在分配资源之前进行判断，只允许不会产生死锁的进程获得资源；

- 我们将系统的状态分为 **安全状态** 和 **不安全状态** ，每当在申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。
- 最具有代表性的 **避免死锁算法** 就是 Dijkstra 的银行家算法，当一个进程申请使用资源的时候，**银行家算法** 通过先 **试探** 分配给该进程资源，然后通过 **安全性算法** 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则 **分配资源给该进程**。

## 4.3 检测死锁

- 对资源的分配加以限制可以 **预防和避免** 死锁的发生，但是都不利于各进程对系统资源的**充分共享**，类比来讲的话，死锁的预防和避免类似于悲观锁，而死锁的检测和解除类似于乐观锁。
- 检测死锁指系统设有**专门的机构**，当死锁发生时，该机构能够检测死锁的发生，并精确地确定与死锁有关的**进程和资源**。

## 4.4 解除死锁

- **立即结束所有进程的执行，重新启动操作系统** ：这种方法简单，但以前所在的工作全部作废，损失很大。
- **撤销涉及死锁的所有进程，解除死锁后继续运行** ：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
- **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
- **抢占资源** ：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除



# 程序计数器为什么是私有的

- 程序计数器私有主要是为了线程切换后能恢复到正确的执行位置

>程序计数器的作用

1.字节码解释器通过改变程序计数器依次读取指令，从而实现**代码的流程控制**，如顺序执行、选择、循环、异常处理等

2.在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程切换回来时能够知道该线程上次**运行的位置**



# 虚拟机栈和本地方法栈为什么是私有的

- 私有的原因是为了保证线程中的局部变量不被其他线程访问到

> 虚拟机栈 & 本地方法栈 

1.虚拟机栈

- 每个java方法在执行的同时会创建一个栈帧(Stack Frame)，用于存储局部变量表、操作数栈、常量池引用等，
- 方法调用到执行完成的过程，就对应着一个栈帧在java虚拟机栈入栈和出栈的过程

2.本地方法栈

- 虚拟机栈为java方法(字节码)服务，本地方法栈则为虚拟机使用到的Native方法服务
- Native方法：java源码中一个方法以"；" 结尾，并且修饰符列表中有”**native**“关键字修饰，底层调用c++写的dll程序；



# 堆和方法区

- 栈内存中存储的**局部变量**，堆内存中存储**实例变量**，方法区内存中存储 **静态变量**
- 三块内存中变化最频繁的是**栈内存**、最先有数据的是**方法区内存**、垃圾回收器主要针对的是**堆内存**
- 堆和方法区是线程共享的，虚拟机栈、本地方法栈、程序计数器是线程私有的
- **变量的分类**
  - 局部变量【方法体内声明】
  - 成员变量【方法体外声明】
    - 实例变量
    - 静态变量



# 串行 & 并发 & 并行

>含义

- 串行：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。
- 并发：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。
- 并行：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。

> 类比

- 串行 = 一个队列和一台咖啡机。
- 并发 = 两个队列和一台咖啡机。
- 并行 = 两个队列和两台咖啡机。

# 多线程的优劣

> 多线程的好处

可以提⾼ CPU 的利⽤率。在多线程程序中，⼀个线程必须等待的时候，CPU 可以运⾏其它的线程⽽不是等待，这样就⼤⼤提⾼了程序的效率。也就是说允许单个程序创建多个线程来完成各⾃的任务。

> 多线程的劣势

多线程需要协调和管理，所以需要占用 CPU 时间来跟踪线程；

线程之间对共享资源的访问会相互影响，必须解决竞⽤共享资源的问题。

线程也是程序，所以线程需要占⽤内存，线程越多占⽤内存也越多；



# 进程&线程&协程

>概念

1.进程

- 进程是程序的一次执行过程，**是操作系统资源分配的最小单位**。

- 进程拥有自己独立的地址空间，有自己的堆，上级挂靠单位是操作系统

2.线程

- 线程，有时被称为轻量级进程(Lightweight Process，LWP），是**操作系统调度（CPU调度）执行的最小单位**。
- 线程是进程的更小的执行单元，多个线程共同协作完成某一项任务

3.协程

-  协程是一种**用户态的轻量级线程**，协程不被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。
-  协程在子程序内部是可中断的，然后转而执行别的子程序，在适当的时候再返回来接着执行。



# 协程 vs 多线程

- 极高的执行效率：因为子程序切换不是线程切换，而是由程序自身控制，因此没有线程切换的开销，和多线程相比，线程数量越多，协程的性能优势就越明显；
- 不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。



# 用户线程 & 守护线程

>概念

**⽤户** (User) **线程**：运⾏在前台，执⾏具体的任务，如程序的主线程、连接⽹络的⼦线程等都是⽤户线程

**守护** (Daemon) **线程**：运⾏在后台，为其他前台线程服务。也可以说守护线程是 JVM 中⾮守护线程的**佣⼈**。⼀旦所有⽤户线程都结束运⾏，守护线程会随 JVM ⼀起结束⼯作

>区别

1.用户线程启动时jvm有可能会启动多个守护线程

- 比如main 函数所在的线程就是⼀个⽤户线程，main 函数启动的同时在 JVM 内部同时还启动了好多守护线程，⽐如垃圾回收线程。

2.⽤户线程结束后JVM 退出，⽽守护线程的存在不会影响 JVM 的退出。

>注意事项

- setDaemon(true)必须在start()⽅法前执⾏，否则会抛出 IllegalThreadStateException 异常
- 在守护线程中产⽣的新线程也是守护线程 
- 不是所有的任务都可以分配给守护线程来执⾏，⽐如读写操作或者计算逻辑 
- 守护 (Daemon) 线程中不能依靠 finally 块的内容来确保执⾏关闭或清理资源的逻辑。因为我们上⾯也说过了⼀旦所有⽤户线程都结束运⾏，守护线程会随 JVM ⼀起结束⼯作，所以守护 (Daemon) 线程中的 finally 语句块可能⽆法被执⾏。



# 创建线程的四种方式

- 继承 Thread 类，重写run()方法

- 实现 Runnable 接⼝，重写run()方法

- 实现 Callable 接⼝，重写call方法，创建FutureTask

- 使⽤ Executors ⼯具类创建线程池，主要有newSingleThreadExecutor，newFixedThreadPool，newCachedThreadPool，

  newScheduledThreadPool



# runnable **和** callable 区别

- Runnable 接⼝ run ⽅法⽆返回值；Callable 接⼝ call ⽅法有返回值，是个泛型，和Future、FutureTask配合可以⽤来获取异步执⾏的结果
- Runnable 接⼝ run ⽅法只能抛出运⾏时异常，且⽆法捕获处理；Callable 接⼝ call ⽅法允许抛出异常，可以获取异常信息、
- Callalbe接⼝⽀持返回执⾏结果，需要调⽤FutureTask.get()得到，此⽅法会阻塞主进程的继续往下执⾏，如果不调⽤不会阻塞。



# **什么是** FutureTask

- FutureTask 表示⼀个异步运算的任务。FutureTask ⾥⾯可以传⼊⼀个 Callable 的具体实现类，可以对这个异步运算的任务的结果进⾏等待获取、判断是否已经完成、取消任务等操作。
- 只有当运算完成的时候结果才能取回，如果运算尚未完成 get ⽅法将会阻塞。⼀个 FutureTask 对象可以对调⽤了 Callable 和Runnable 的对象进⾏包装，由于 FutureTask 也是Runnable 接⼝的实现类，所以 FutureTask 也可以放⼊线程池中



# 线程调度器(Thread Scheduler)和时间分片(Time Slicing )

线程调度器是⼀个操作系统服务，它负责为 Runnable 状态的线程分配 CPU 时间。⼀旦我们创建⼀个线程并启动它，它的执⾏便依赖于线程调度器的实现。

时间分⽚是指将可⽤的 CPU 时间分配给可⽤的 Runnable 线程的过程，分配 CPU 时间可以基于**线程优先级或者线程等待的时间**。



# 线程调度算法的两种模型

分时调度模型和抢占式调度模型

分时调度模型是指让所有的线程轮流获得 cpu 的使⽤权，并且平均分配每个线程占⽤的 CPU 的时间⽚

抢占式调度模型，是指优先让可运⾏池中优先级⾼的线程占⽤CPU，如果可运⾏池中的线程优先级相同，那么就随机选择⼀个线程，使其占⽤CPU。处于运⾏状态的线程会⼀直运⾏，直⾄它不得不放弃 CPU。



# java采用哪种线程调度算法

抢占式调度模型



# 线程的生命周期和状态

>状态介绍

1.线程有6种状态，分别为新创建、可运行、等待、计时等待、阻塞、终止

>状态转换

2.6种状态之间的转换如下

- 线程创建后处于**New**状态，调用start()后开始运行，线程处于**Ready**状态，获得cpu时间片后处于**Running**状态;(ready和running统称为runnable可运行态)
- 当线程执行wait()方法后，进入**Waiting**状态，进入waiting状态的线程需要依靠其他线程的通知才能够返回到运行状态
- 当线程执行的sleep(long millis)或wait(long millis)方法后，进入**Timed_Waiting**状态，计时等待相当于是在等待的基础上增加了超时限制，当等待时间结束后线程自动进入到**Runnable**状态，而无需唤醒。
- 当线程调用同步方法，在没有获得锁的情况下，线程会进入到**Blocked**阻塞状态
- 线程的run()方法执行完后，进入**Terminated**状态。

![img](https://javaguide.cn/assets/java-life-cycle.e81ded7b.png)

# sleep() & wait() 

- 类的不同：sleep() 是 Thread线程类的静态⽅法，wait() 是 Object类的⽅法
- 是否释放锁：sleep()方法不释放锁，而wait()方法释放了锁
- 是否让出cpu时间片：二者均会使线程让出cpu时间片
- ⽤途不同：Wait 通常被⽤于线程间交互/通信，sleep 通常被⽤于暂停执⾏。

- 用法不同：`wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll()` 方法。`sleep() `方法执行完成后，线程会自动苏醒，或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。



# 调用wait() 使用 if 块还是while循环

- 应该使用while(condition)循环，if可能出现假唤醒，因为当wait这步被唤醒时，很可能condition已经不满足了，所以还需要判断condition。

>举例，假如使用if

- 当a线程获得锁，发现条件不满足则执行wait()进入等待
- 接着b线程获得锁，也发现条件不满足则执行wait()进入等待
- 此时条件满足，使用notifyAll唤醒所有线程，线程a首先获得锁，执行业务代码，假如执行之后唤醒所有线程并且此时条件不再满足；
- 此时b线程获得锁继续向下执行，其实此时条件已经不再满足，而if块只会执行一次，因此会出现假唤醒。

```java
synchronized (obj) {

while (condition does not hold)

obj.wait(); // (Releases lock, and reacquires on wakeup)

... // Perform action appropriate to condition

}
```



# 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

>结论

- 调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行

>解释

- `start()`方法的作用是启动一个**分支线程**，在`JVM`中开辟一个**新的栈空间**，这段代码的任务只是为了开启一个新的栈空间，只要新的栈空间开出来，`start()`方法就结束了。线程启动成功，线程启动成功之后会自动调用`run`方法，并且run方法在分支栈的**栈底部**。`main`方法在主栈的栈底部。`run`和`main`是平级的。

- 但是，直接执行 `run()` 方法世实际上并没有开启线程，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。



# synchronized 关键字

>介绍

- `synchronized` 关键字解决了多个线程之间访问资源的同步性
- `synchronized`关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

>构造方法使用synchronized 关键字

- 构造方法不能使用 synchronized 关键字修饰
- 构造方法本身就属于线程安全的，不存在同步的构造方法一说。 

## 三种使用方式

**1.修饰实例方法:**   作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁

**2.修饰静态方法:**   给当前类加锁，作用于类的所有对象实例，进入同步代码前要获得当前class的锁

```java
synchronized static void method() {
    //业务代码
}
```

**3.修饰代码块:**   指定加锁对象，对给定对象/类加锁

```java
// 进入同步代码块前获得给定对象的锁
synchronized(this) {
    //业务代码
}
// 进入同步代码块前获得当前class的锁
synchronized(类.class) {
    //业务代码
}
```

## synchronized 关键字的底层原理

- `synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

- `synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。

**不过两者的本质都是对对象监视器 monitor 的获取。**



#  CPU缓存模型

>cpu缓存 & 内存缓存

- CPU Cache 缓存的是内存数据用于解决 CPU 处理速度和内存不匹配的问题
- 内存缓存的是硬盘数据用于解决硬盘访问速度过慢的问题。

>cpu缓存的工作方式

- 先复制一份数据到 CPU 缓存中，当 CPU 需要用到的时候就可以直接从 CPU Cache 中读取数据，当运算完成后，再将运算得到的数据写回 Main Memory 中
- 存在的 **内存缓存不一致性的问题**，需通过制定缓存一致协议解决。

![cpu-cache](https://javaguide.cn/assets/cpu-cache.cea66e7e.png)



# volatile 关键字

>jmm

- 在jdk1.2之前，java的内存模型总是在主存中读取变量，没有任何问题
- 为了提高执行速度新增了本地内存，有了本地内存后，线程可以将变量存储在本地内存(共享变量的副本)中，而不是直接在主存中读写，有可能会造成**数据的不一致**，因此需要将变量声明为volatile

>volatile 变量

- 在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比sychronized关键字更轻量级的同步机制

- 变量声明为volatile，表明该变量共享且不稳定，JMM会把该线程本地内存中的变量强制**刷新到主内存**中去，每次使用该变量均需要去主存中读取，修改后再写回主存，写操作会导致其他线程中的volatile变量缓存无效，将变量的更新操作**通知到其他线程**，保证了变量的可见性；
- volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器**重排序**；

>重排序

-  重排序是指编译器和处理器为了优化程序性能而对指令序列进行排序的一种手段，重排序需要遵守一定规则：
   - 重排序操作不会对存在数据依赖关系的操作进行重排序；
   - 重排序是为了优化性能，但是不管怎么重排序，单线程下程序的执行结果不能被改变



# 池化技术

- 例如线程池、数据库连接池、http连接池，池化技术是为了减少每次获取资源的消耗，提高对资源的利用率。



# 为什么使用线程池

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行**统一的分配、调优和监控**。



# 如何创建线程池

**方式一：通过构造方法实现**   ThredPoolExecutor()

**方式二：通过Executors工具类实现** ，该工具类可以创建三种类型的ThreadPoolExecutor

- **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
- **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
- **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。
- **ScheduledThreadPool：**通过Executors的newScheduledThreadPool方式创建，ScheduledThreadPool这类线程池主要用于执行定时任务和具有固定时期的重复任务。



# Executors 返回线程池对象的弊端

- **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。
- **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。



# ThreadPoolExecutor

> ThreadPoolExecutor 3 个最重要的参数

- **`corePoolSize` :** 核心线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

> ThreadPoolExecutor其他常见参数:

1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. **`unit`** : `keepAliveTime` 参数的时间单位。
3. **`threadFactory`** :executor 创建新线程的时候会用到。
4. **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。

>饱和策略

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，ThreadPoolTaskExecutor 定义一些策略:

- **ThreadPoolExecutor.AbortPolicy：** 抛出 RejectedExecutionException来拒绝新任务的处理。
- **ThreadPoolExecutor.CallerRunsPolicy：** 调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。
- **ThreadPoolExecutor.DiscardPolicy：** 不处理新任务，直接丢弃掉。
- **ThreadPoolExecutor.DiscardOldestPolicy：** 此策略将丢弃最早的未处理的任务请求。



# 线程池执行的过程

执行过程如下图。

![图解线程池实现原理](https://javaguide.cn/assets/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.2b9eb21a.png)



# 线程池大小确定

>背景

- 如果我们设置的线程池数量太小的话，如果同一时间有大量任务/请求需要处理，可能会导致大量的请求/任务在任务队列中排队等待执行，甚至会出现任务队列满了之后任务/请求无法处理的情况，或者大量任务堆积在任务队列导致 OOM。这样很明显是有问题的！ CPU 根本没有得到充分利用。
- 如果我们设置线程数量太大，大量线程可能会同时在争取 CPU 资源，这样会导致大量的上下文切换，从而增加线程的执行时间，影响了整体执行效率。

>常用公式

- **CPU 密集型任务(N+1)：** 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。
- **I/O 密集型任务(2N)：** 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

> CPU 密集任务 & IO 密集任务

- CPU 密集型简单理解就是利用 CPU 计算能力的任务，比如你在内存中对大量数据进行排序
- 但凡涉及到网络读取，文件读取这类都是 IO 密集型，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。





